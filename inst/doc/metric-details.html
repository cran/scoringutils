<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />

<meta name="viewport" content="width=device-width, initial-scale=1" />

<meta name="author" content="Nikos Bosse" />

<meta name="date" content="2022-05-13" />

<title>Details on the metrics implemented in scoringutils</title>

<script>// Pandoc 2.9 adds attributes on both header and div. We remove the former (to
// be compatible with the behavior of Pandoc < 2.8).
document.addEventListener('DOMContentLoaded', function(e) {
  var hs = document.querySelectorAll("div.section[class*='level'] > :first-child");
  var i, h, a;
  for (i = 0; i < hs.length; i++) {
    h = hs[i];
    if (!/^h[1-6]$/i.test(h.tagName)) continue;  // it should be a header h1-h6
    a = h.attributes;
    while (a.length > 0) h.removeAttribute(a[0].name);
  }
});
</script>
<script>$(document).ready(function(){
    if (typeof $('[data-toggle="tooltip"]').tooltip === 'function') {
        $('[data-toggle="tooltip"]').tooltip();
    }
    if ($('[data-toggle="popover"]').popover === 'function') {
        $('[data-toggle="popover"]').popover();
    }
});
</script>
<style type="text/css">
.lightable-minimal {
border-collapse: separate;
border-spacing: 16px 1px;
width: 100%;
margin-bottom: 10px;
}
.lightable-minimal td {
margin-left: 5px;
margin-right: 5px;
}
.lightable-minimal th {
margin-left: 5px;
margin-right: 5px;
}
.lightable-minimal thead tr:last-child th {
border-bottom: 2px solid #00000050;
empty-cells: hide;
}
.lightable-minimal tbody tr:first-child td {
padding-top: 0.5em;
}
.lightable-minimal.lightable-hover tbody tr:hover {
background-color: #f5f5f5;
}
.lightable-minimal.lightable-striped tbody tr:nth-child(even) {
background-color: #f5f5f5;
}
.lightable-classic {
border-top: 0.16em solid #111111;
border-bottom: 0.16em solid #111111;
width: 100%;
margin-bottom: 10px;
margin: 10px 5px;
}
.lightable-classic tfoot tr td {
border: 0;
}
.lightable-classic tfoot tr:first-child td {
border-top: 0.14em solid #111111;
}
.lightable-classic caption {
color: #222222;
}
.lightable-classic td {
padding-left: 5px;
padding-right: 5px;
color: #222222;
}
.lightable-classic th {
padding-left: 5px;
padding-right: 5px;
font-weight: normal;
color: #222222;
}
.lightable-classic thead tr:last-child th {
border-bottom: 0.10em solid #111111;
}
.lightable-classic.lightable-hover tbody tr:hover {
background-color: #F9EEC1;
}
.lightable-classic.lightable-striped tbody tr:nth-child(even) {
background-color: #f5f5f5;
}
.lightable-classic-2 {
border-top: 3px double #111111;
border-bottom: 3px double #111111;
width: 100%;
margin-bottom: 10px;
}
.lightable-classic-2 tfoot tr td {
border: 0;
}
.lightable-classic-2 tfoot tr:first-child td {
border-top: 3px double #111111;
}
.lightable-classic-2 caption {
color: #222222;
}
.lightable-classic-2 td {
padding-left: 5px;
padding-right: 5px;
color: #222222;
}
.lightable-classic-2 th {
padding-left: 5px;
padding-right: 5px;
font-weight: normal;
color: #222222;
}
.lightable-classic-2 tbody tr:last-child td {
border-bottom: 3px double #111111;
}
.lightable-classic-2 thead tr:last-child th {
border-bottom: 1px solid #111111;
}
.lightable-classic-2.lightable-hover tbody tr:hover {
background-color: #F9EEC1;
}
.lightable-classic-2.lightable-striped tbody tr:nth-child(even) {
background-color: #f5f5f5;
}
.lightable-material {
min-width: 100%;
white-space: nowrap;
table-layout: fixed;
font-family: Roboto, sans-serif;
border: 1px solid #EEE;
border-collapse: collapse;
margin-bottom: 10px;
}
.lightable-material tfoot tr td {
border: 0;
}
.lightable-material tfoot tr:first-child td {
border-top: 1px solid #EEE;
}
.lightable-material th {
height: 56px;
padding-left: 16px;
padding-right: 16px;
}
.lightable-material td {
height: 52px;
padding-left: 16px;
padding-right: 16px;
border-top: 1px solid #eeeeee;
}
.lightable-material.lightable-hover tbody tr:hover {
background-color: #f5f5f5;
}
.lightable-material.lightable-striped tbody tr:nth-child(even) {
background-color: #f5f5f5;
}
.lightable-material.lightable-striped tbody td {
border: 0;
}
.lightable-material.lightable-striped thead tr:last-child th {
border-bottom: 1px solid #ddd;
}
.lightable-material-dark {
min-width: 100%;
white-space: nowrap;
table-layout: fixed;
font-family: Roboto, sans-serif;
border: 1px solid #FFFFFF12;
border-collapse: collapse;
margin-bottom: 10px;
background-color: #363640;
}
.lightable-material-dark tfoot tr td {
border: 0;
}
.lightable-material-dark tfoot tr:first-child td {
border-top: 1px solid #FFFFFF12;
}
.lightable-material-dark th {
height: 56px;
padding-left: 16px;
padding-right: 16px;
color: #FFFFFF60;
}
.lightable-material-dark td {
height: 52px;
padding-left: 16px;
padding-right: 16px;
color: #FFFFFF;
border-top: 1px solid #FFFFFF12;
}
.lightable-material-dark.lightable-hover tbody tr:hover {
background-color: #FFFFFF12;
}
.lightable-material-dark.lightable-striped tbody tr:nth-child(even) {
background-color: #FFFFFF12;
}
.lightable-material-dark.lightable-striped tbody td {
border: 0;
}
.lightable-material-dark.lightable-striped thead tr:last-child th {
border-bottom: 1px solid #FFFFFF12;
}
.lightable-paper {
width: 100%;
margin-bottom: 10px;
color: #444;
}
.lightable-paper tfoot tr td {
border: 0;
}
.lightable-paper tfoot tr:first-child td {
border-top: 1px solid #00000020;
}
.lightable-paper thead tr:last-child th {
color: #666;
vertical-align: bottom;
border-bottom: 1px solid #00000020;
line-height: 1.15em;
padding: 10px 5px;
}
.lightable-paper td {
vertical-align: middle;
border-bottom: 1px solid #00000010;
line-height: 1.15em;
padding: 7px 5px;
}
.lightable-paper.lightable-hover tbody tr:hover {
background-color: #F9EEC1;
}
.lightable-paper.lightable-striped tbody tr:nth-child(even) {
background-color: #00000008;
}
.lightable-paper.lightable-striped tbody td {
border: 0;
}
</style>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>







<style type="text/css">body {
background-color: #fff;
margin: 1em auto;
max-width: 700px;
overflow: visible;
padding-left: 2em;
padding-right: 2em;
font-family: "Open Sans", "Helvetica Neue", Helvetica, Arial, sans-serif;
font-size: 14px;
line-height: 1.35;
}
#TOC {
clear: both;
margin: 0 0 10px 10px;
padding: 4px;
width: 400px;
border: 1px solid #CCCCCC;
border-radius: 5px;
background-color: #f6f6f6;
font-size: 13px;
line-height: 1.3;
}
#TOC .toctitle {
font-weight: bold;
font-size: 15px;
margin-left: 5px;
}
#TOC ul {
padding-left: 40px;
margin-left: -1.5em;
margin-top: 5px;
margin-bottom: 5px;
}
#TOC ul ul {
margin-left: -2em;
}
#TOC li {
line-height: 16px;
}
table {
margin: 1em auto;
border-width: 1px;
border-color: #DDDDDD;
border-style: outset;
border-collapse: collapse;
}
table th {
border-width: 2px;
padding: 5px;
border-style: inset;
}
table td {
border-width: 1px;
border-style: inset;
line-height: 18px;
padding: 5px 5px;
}
table, table th, table td {
border-left-style: none;
border-right-style: none;
}
table thead, table tr.even {
background-color: #f7f7f7;
}
p {
margin: 0.5em 0;
}
blockquote {
background-color: #f6f6f6;
padding: 0.25em 0.75em;
}
hr {
border-style: solid;
border: none;
border-top: 1px solid #777;
margin: 28px 0;
}
dl {
margin-left: 0;
}
dl dd {
margin-bottom: 13px;
margin-left: 13px;
}
dl dt {
font-weight: bold;
}
ul {
margin-top: 0;
}
ul li {
list-style: circle outside;
}
ul ul {
margin-bottom: 0;
}
pre, code {
background-color: #f7f7f7;
border-radius: 3px;
color: #333;
white-space: pre-wrap; 
}
pre {
border-radius: 3px;
margin: 5px 0px 10px 0px;
padding: 10px;
}
pre:not([class]) {
background-color: #f7f7f7;
}
code {
font-family: Consolas, Monaco, 'Courier New', monospace;
font-size: 85%;
}
p > code, li > code {
padding: 2px 0px;
}
div.figure {
text-align: center;
}
img {
background-color: #FFFFFF;
padding: 2px;
border: 1px solid #DDDDDD;
border-radius: 3px;
border: 1px solid #CCCCCC;
margin: 0 5px;
}
h1 {
margin-top: 0;
font-size: 35px;
line-height: 40px;
}
h2 {
border-bottom: 4px solid #f7f7f7;
padding-top: 10px;
padding-bottom: 2px;
font-size: 145%;
}
h3 {
border-bottom: 2px solid #f7f7f7;
padding-top: 10px;
font-size: 120%;
}
h4 {
border-bottom: 1px solid #f7f7f7;
margin-left: 8px;
font-size: 105%;
}
h5, h6 {
border-bottom: 1px solid #ccc;
font-size: 105%;
}
a {
color: #0033dd;
text-decoration: none;
}
a:hover {
color: #6666ff; }
a:visited {
color: #800080; }
a:visited:hover {
color: #BB00BB; }
a[href^="http:"] {
text-decoration: underline; }
a[href^="https:"] {
text-decoration: underline; }

code > span.kw { color: #555; font-weight: bold; } 
code > span.dt { color: #902000; } 
code > span.dv { color: #40a070; } 
code > span.bn { color: #d14; } 
code > span.fl { color: #d14; } 
code > span.ch { color: #d14; } 
code > span.st { color: #d14; } 
code > span.co { color: #888888; font-style: italic; } 
code > span.ot { color: #007020; } 
code > span.al { color: #ff0000; font-weight: bold; } 
code > span.fu { color: #900; font-weight: bold; } 
code > span.er { color: #a61717; background-color: #e3d2d2; } 
</style>




</head>

<body>




<h1 class="title toc-ignore">Details on the metrics implemented in
<code>scoringutils</code></h1>
<h4 class="author">Nikos Bosse</h4>
<h4 class="date">2022-05-13</h4>



<div id="applicability-of-different-metrics-for-different-types-of-forecasts-and-formats" class="section level2">
<h2>Applicability of different metrics for different types of forecasts
and formats</h2>
<p>This table gives an overview for when which metric can be applied and
gives a very brief description. Note that this table on shows the
metrics as implemented in <code>scoringutils</code>. For example, only
scoring of sample-based discrete and continuous distributions is
implemented in <code>scoringutils</code>, but closed-form solutions
often exist (e.g. in the <code>scoringRules</code> package).</p>
<table class="table" style="margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="empty-cells: hide;border-bottom:hidden;" colspan="1">
</th>
<th style="border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; " colspan="2">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px; ">
Sample-based
</div>
</th>
<th style="empty-cells: hide;border-bottom:hidden;" colspan="3">
</th>
</tr>
<tr>
<th style="text-align:left;">
Metric
</th>
<th style="text-align:center;">
D
</th>
<th style="text-align:center;">
C
</th>
<th style="text-align:center;">
B
</th>
<th style="text-align:center;">
Q
</th>
<th style="text-align:left;">
Info
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;width: 3.2cm; background-color: Gainsboro !important;">
Absolute error
</td>
<td style="text-align:center;width: 1.5cm; background-color: Gainsboro !important;">
y
</td>
<td style="text-align:center;width: 1.5cm; background-color: Gainsboro !important;">
y
</td>
<td style="text-align:center;width: 1.3cm; background-color: Gainsboro !important;">
n
</td>
<td style="text-align:center;width: 1.5cm; background-color: Gainsboro !important;">
y
</td>
<td style="text-align:left;width: 6.0cm; background-color: Gainsboro !important;">
Suitable for scoring the median of a predictive distribution
</td>
</tr>
<tr>
<td style="text-align:left;width: 3.2cm; ">
Absolute error
</td>
<td style="text-align:center;width: 1.5cm; ">
y
</td>
<td style="text-align:center;width: 1.5cm; ">
y
</td>
<td style="text-align:center;width: 1.3cm; ">
n
</td>
<td style="text-align:center;width: 1.5cm; ">
y
</td>
<td style="text-align:left;width: 6.0cm; ">
Suitable for scoring the median of a predictive distribution
</td>
</tr>
<tr>
<td style="text-align:left;width: 3.2cm; background-color: Gainsboro !important;">
Squared error
</td>
<td style="text-align:center;width: 1.5cm; background-color: Gainsboro !important;">
y
</td>
<td style="text-align:center;width: 1.5cm; background-color: Gainsboro !important;">
y
</td>
<td style="text-align:center;width: 1.3cm; background-color: Gainsboro !important;">
n
</td>
<td style="text-align:center;width: 1.5cm; background-color: Gainsboro !important;">
y
</td>
<td style="text-align:left;width: 6.0cm; background-color: Gainsboro !important;">
Suitable for scoring the mean of a predictive distribution.
</td>
</tr>
<tr>
<td style="text-align:left;width: 3.2cm; ">
Squared error
</td>
<td style="text-align:center;width: 1.5cm; ">
y
</td>
<td style="text-align:center;width: 1.5cm; ">
y
</td>
<td style="text-align:center;width: 1.3cm; ">
n
</td>
<td style="text-align:center;width: 1.5cm; ">
y
</td>
<td style="text-align:left;width: 6.0cm; ">
Suitable for scoring the mean of a predictive distribution.
</td>
</tr>
<tr>
<td style="text-align:left;width: 3.2cm; background-color: Gainsboro !important;">
(Continuous) ranked probability score (CRPS)
</td>
<td style="text-align:center;width: 1.5cm; background-color: Gainsboro !important;">
y
</td>
<td style="text-align:center;width: 1.5cm; background-color: Gainsboro !important;">
y
</td>
<td style="text-align:center;width: 1.3cm; background-color: Gainsboro !important;">
n
</td>
<td style="text-align:center;width: 1.5cm; background-color: Gainsboro !important;">
n
</td>
<td style="text-align:left;width: 6.0cm; background-color: Gainsboro !important;">
Proper scoring rule (smaller is better), takes entire predictive
distribution into account (global), penalises over- and under-confidence
similarly, stable handling of outliers
</td>
</tr>
<tr>
<td style="text-align:left;width: 3.2cm; ">
Log score
</td>
<td style="text-align:center;width: 1.5cm; ">
n
</td>
<td style="text-align:center;width: 1.5cm; ">
y
</td>
<td style="text-align:center;width: 1.3cm; ">
y
</td>
<td style="text-align:center;width: 1.5cm; ">
n
</td>
<td style="text-align:left;width: 6.0cm; ">
Proper scoring rule, smaller is better, only evaluates predictive
density at observed value (local), penalises over-confidence severely,
susceptible to outliers
</td>
</tr>
<tr>
<td style="text-align:left;width: 3.2cm; background-color: Gainsboro !important;">
(Weighted) interval score (WIS)
</td>
<td style="text-align:center;width: 1.5cm; background-color: Gainsboro !important;">
y
</td>
<td style="text-align:center;width: 1.5cm; background-color: Gainsboro !important;">
y
</td>
<td style="text-align:center;width: 1.3cm; background-color: Gainsboro !important;">
n
</td>
<td style="text-align:center;width: 1.5cm; background-color: Gainsboro !important;">
y
</td>
<td style="text-align:left;width: 6.0cm; background-color: Gainsboro !important;">
Proper scoring rule, smaller is better, similar properties to CRPS and
converges to CRPS for an increasing number of equally spaced intervals
</td>
</tr>
<tr>
<td style="text-align:left;width: 3.2cm; ">
Dawid-Sebastiani score (DSS)
</td>
<td style="text-align:center;width: 1.5cm; ">
y
</td>
<td style="text-align:center;width: 1.5cm; ">
y
</td>
<td style="text-align:center;width: 1.3cm; ">
n
</td>
<td style="text-align:center;width: 1.5cm; ">
n
</td>
<td style="text-align:left;width: 6.0cm; ">
Proper scoring rule, smaller is better, evaluates forecast based on mean
and sd of predictive distribution (global), susceptible to outliers,
penalises over-confidence severely
</td>
</tr>
<tr>
<td style="text-align:left;width: 3.2cm; background-color: Gainsboro !important;">
Brier score (BS)
</td>
<td style="text-align:center;width: 1.5cm; background-color: Gainsboro !important;">
n
</td>
<td style="text-align:center;width: 1.5cm; background-color: Gainsboro !important;">
n
</td>
<td style="text-align:center;width: 1.3cm; background-color: Gainsboro !important;">
y
</td>
<td style="text-align:center;width: 1.5cm; background-color: Gainsboro !important;">
n
</td>
<td style="text-align:left;width: 6.0cm; background-color: Gainsboro !important;">
Proper scoring rule, smaller is better, equals CRPS for binary outcomes,
penalises over- and under-confidence similarly
</td>
</tr>
<tr>
<td style="text-align:left;width: 3.2cm; ">
Interval coverage
</td>
<td style="text-align:center;width: 1.5cm; ">
n
</td>
<td style="text-align:center;width: 1.5cm; ">
n
</td>
<td style="text-align:center;width: 1.3cm; ">
n
</td>
<td style="text-align:center;width: 1.5cm; ">
y
</td>
<td style="text-align:left;width: 6.0cm; ">
Proportion of observations falling inside a given central prediction
interval (= ‘empirical interval coverage’). Used to assess probabilistic
calibration.
</td>
</tr>
<tr>
<td style="text-align:left;width: 3.2cm; background-color: Gainsboro !important;">
Coverage deviation
</td>
<td style="text-align:center;width: 1.5cm; background-color: Gainsboro !important;">
n
</td>
<td style="text-align:center;width: 1.5cm; background-color: Gainsboro !important;">
n
</td>
<td style="text-align:center;width: 1.3cm; background-color: Gainsboro !important;">
n
</td>
<td style="text-align:center;width: 1.5cm; background-color: Gainsboro !important;">
y
</td>
<td style="text-align:left;width: 6.0cm; background-color: Gainsboro !important;">
Average difference between empirical and nominal interval coverage
(coverage that should have been realised)
</td>
</tr>
<tr>
<td style="text-align:left;width: 3.2cm; ">
Quantile coverage
</td>
<td style="text-align:center;width: 1.5cm; ">
y
</td>
<td style="text-align:center;width: 1.5cm; ">
y
</td>
<td style="text-align:center;width: 1.3cm; ">
n
</td>
<td style="text-align:center;width: 1.5cm; ">
n
</td>
<td style="text-align:left;width: 6.0cm; ">
Proportion of observations below a given quantile of the predictive CDF.
Used to assess probabilistic calibration.
</td>
</tr>
<tr>
<td style="text-align:left;width: 3.2cm; background-color: Gainsboro !important;">
Dispersion
</td>
<td style="text-align:center;width: 1.5cm; background-color: Gainsboro !important;">
n
</td>
<td style="text-align:center;width: 1.5cm; background-color: Gainsboro !important;">
n
</td>
<td style="text-align:center;width: 1.3cm; background-color: Gainsboro !important;">
n
</td>
<td style="text-align:center;width: 1.5cm; background-color: Gainsboro !important;">
y
</td>
<td style="text-align:left;width: 6.0cm; background-color: Gainsboro !important;">
Dispersion component of WIS, measures width of predictive intervals.
</td>
</tr>
<tr>
<td style="text-align:left;width: 3.2cm; ">
Median Absolute Deviation (Dispersion)
</td>
<td style="text-align:center;width: 1.5cm; ">
y
</td>
<td style="text-align:center;width: 1.5cm; ">
y
</td>
<td style="text-align:center;width: 1.3cm; ">
n
</td>
<td style="text-align:center;width: 1.5cm; ">
n
</td>
<td style="text-align:left;width: 6.0cm; ">
Measure for dispersion of a forecast: median of the absolute deviations
from the median
</td>
</tr>
<tr>
<td style="text-align:left;width: 3.2cm; background-color: Gainsboro !important;">
Under-, Over-prediction
</td>
<td style="text-align:center;width: 1.5cm; background-color: Gainsboro !important;">
n
</td>
<td style="text-align:center;width: 1.5cm; background-color: Gainsboro !important;">
n
</td>
<td style="text-align:center;width: 1.3cm; background-color: Gainsboro !important;">
n
</td>
<td style="text-align:center;width: 1.5cm; background-color: Gainsboro !important;">
y
</td>
<td style="text-align:left;width: 6.0cm; background-color: Gainsboro !important;">
Absolute amount of over-or under-prediction (components of WIS)
</td>
</tr>
<tr>
<td style="text-align:left;width: 3.2cm; ">
Under-, Over-prediction
</td>
<td style="text-align:center;width: 1.5cm; ">
n
</td>
<td style="text-align:center;width: 1.5cm; ">
n
</td>
<td style="text-align:center;width: 1.3cm; ">
n
</td>
<td style="text-align:center;width: 1.5cm; ">
y
</td>
<td style="text-align:left;width: 6.0cm; ">
Absolute amount of over-or under-prediction (components of WIS)
</td>
</tr>
<tr>
<td style="text-align:left;width: 3.2cm; background-color: Gainsboro !important;">
Probability integral transform (PIT)
</td>
<td style="text-align:center;width: 1.5cm; background-color: Gainsboro !important;">
y
</td>
<td style="text-align:center;width: 1.5cm; background-color: Gainsboro !important;">
y
</td>
<td style="text-align:center;width: 1.3cm; background-color: Gainsboro !important;">
n
</td>
<td style="text-align:center;width: 1.5cm; background-color: Gainsboro !important;">
y
</td>
<td style="text-align:left;width: 6.0cm; background-color: Gainsboro !important;">
PIT transform is the CDF of the predictive distribution evaluated at the
observed values. PIT values should be uniform.
</td>
</tr>
<tr>
<td style="text-align:left;width: 3.2cm; ">
Dispersion
</td>
<td style="text-align:center;width: 1.5cm; ">
n
</td>
<td style="text-align:center;width: 1.5cm; ">
n
</td>
<td style="text-align:center;width: 1.3cm; ">
n
</td>
<td style="text-align:center;width: 1.5cm; ">
y
</td>
<td style="text-align:left;width: 6.0cm; ">
Dispersion component of WIS, measures width of predictive intervals.
</td>
</tr>
<tr>
<td style="text-align:left;width: 3.2cm; background-color: Gainsboro !important;">
Bias
</td>
<td style="text-align:center;width: 1.5cm; background-color: Gainsboro !important;">
y
</td>
<td style="text-align:center;width: 1.5cm; background-color: Gainsboro !important;">
y
</td>
<td style="text-align:center;width: 1.3cm; background-color: Gainsboro !important;">
n
</td>
<td style="text-align:center;width: 1.5cm; background-color: Gainsboro !important;">
y
</td>
<td style="text-align:left;width: 6.0cm; background-color: Gainsboro !important;">
Measure of relative tendency to over- or under-predict (aspect of
calibration), bounded between -1 and 1 (ideally 0)
</td>
</tr>
<tr>
<td style="text-align:left;width: 3.2cm; ">
Mean score ratio
</td>
<td style="text-align:center;width: 1.5cm; ">
~
</td>
<td style="text-align:center;width: 1.5cm; ">
~
</td>
<td style="text-align:center;width: 1.3cm; ">
~
</td>
<td style="text-align:center;width: 1.5cm; ">
~
</td>
<td style="text-align:left;width: 6.0cm; ">
Compares performance of two models. Properties depend on the metric
chosen for the comparison.
</td>
</tr>
<tr>
<td style="text-align:left;width: 3.2cm; background-color: Gainsboro !important;">
(Scaled) Relative skill
</td>
<td style="text-align:center;width: 1.5cm; background-color: Gainsboro !important;">
~
</td>
<td style="text-align:center;width: 1.5cm; background-color: Gainsboro !important;">
~
</td>
<td style="text-align:center;width: 1.3cm; background-color: Gainsboro !important;">
~
</td>
<td style="text-align:center;width: 1.5cm; background-color: Gainsboro !important;">
~
</td>
<td style="text-align:left;width: 6.0cm; background-color: Gainsboro !important;">
Ranks models based on pairwise comparisons, useful in the context of
missing forecasts. Properties depend on the metric chosen for the
comparison.
</td>
</tr>
<tr>
<td style="text-align:left;width: 3.2cm; ">
(Scaled) Relative skill
</td>
<td style="text-align:center;width: 1.5cm; ">
~
</td>
<td style="text-align:center;width: 1.5cm; ">
~
</td>
<td style="text-align:center;width: 1.3cm; ">
~
</td>
<td style="text-align:center;width: 1.5cm; ">
~
</td>
<td style="text-align:left;width: 6.0cm; ">
Ranks models based on pairwise comparisons, useful in the context of
missing forecasts. Properties depend on the metric chosen for the
comparison.
</td>
</tr>
</tbody>
</table>
</div>
<div id="detailed-explanation-of-the-metrics-implemented-in-scoringutils" class="section level2">
<h2>Detailed explanation of the metrics implemented in
<code>scoringutils</code></h2>
<table class="table" style="margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
Metric
</th>
<th style="text-align:left;">
Explanation
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;width: 3.5cm; background-color: Gainsboro !important;">
CRPS (Continuous) ranked probability score
</td>
<td style="text-align:left;background-color: Gainsboro !important;width: 15.5cm; ">
<p>The crps is a proper scoring rule that generalises the absolute error
to probabilistic forecasts. It measures the ‘distance’ of the predictive
distribution to the observed data-generating distribution. The CRPS is
given as <span class="math display">\[\text{CRPS}(F, y) =
\int_{-\infty}^\infty \left( F(x) - 1(x \geq y) \right)^2 dx,\]</span>
where y is the true observed value and F the CDF of predictive
distribution. Often An alternative representation is used: <span class="math display">\[ \text{CRPS}(F, y) = \frac{1}{2} \mathbb{E}_{F}
|X - X&#39;| - \mathbb{E}_P |X - y|,\]</span> where <span class="math inline">\(X\)</span> and <span class="math inline">\(X&#39;\)</span> are independent realisations from
the predictive distributions <span class="math inline">\(F\)</span> with
finite first moment and <span class="math inline">\(y\)</span> is the
true value. In this represenation we can simply replace <span class="math inline">\(X\)</span> and <span class="math inline">\(X&#39;\)</span> by samples sum over all possible
combinations to obtain the CRPS. For integer-valued forecasts, the RPS
is given as <span class="math display">\[ \text{RPS}(F, y) = \sum_{x =
0}^\infty (F(x) - 1(x \geq y))^2. \]</span></p>
<strong>Usage and caveats</strong> Smaller values are better. The crps
is a good choice for most practical purposes that involve decision
making, as it takes the entire predictive distribution into account. If
two forecasters assign the same probability to the true event <span class="math inline">\(y\)</span>, then the forecaster who assigned high
probability to events far away from <span class="math inline">\(y\)</span> will still get a worse score. The crps
(in contrast to the log score) can at times be quite lenient towards
extreme mispredictions. Also, due to it’s similarity to the absolute
error, the level of scores depend a lot on the absolute value of what is
predicted, which makes it hard to compare scores of forecasts for
quantities that are orders of magnitude apart.
</td>
</tr>
<tr>
<td style="text-align:left;width: 3.5cm; ">
Log score
</td>
<td style="text-align:left;width: 15.5cm; ">
<p>The Log score is a proper scoring rule that is simply compuated as
the log of the predictive density evaluated at the true observed value.
It is given as <span class="math display">\[ \text{log score} = \log
f(y), \]</span> where <span class="math inline">\(f\)</span> is the
predictive density function and y is the true value. For integer-valued
forecasts, the log score can be computed as <span class="math display">\[ \text{log score} = \log p_y, \]</span> where
<span class="math inline">\(p_y\)</span> is the probability assigned to
outcome p by the forecast F.</p>
<strong>Usage and caveats</strong>: Larger values are better, but
sometimes the sign is reversed. The log score is ensitive to outliers,
as individual negative log score contributions quickly can become very
large if the event falls in the tails of the predictive distribution,
where <span class="math inline">\(f(y)\)</span> (or <span class="math inline">\(p_y\)</span>) is close to zero. Whether or not
that is desirable depends ont the application. In scoringutils, the log
score cannot be used for integer-valued forecasts, as the implementation
requires a predictive density. In contrast to the crps, the log score is
a local scoring rule: it’s value only depends only on the probability
that was assigned to the actual outcome. This property may be desirable
for inferential purposes, for example in a Bayesian context (Winkler et
al., 1996). In settings where forecasts inform decision making, it may
be more appropriate to score forecasts based on the entire predictive
distribution.
</td>
</tr>
<tr>
<td style="text-align:left;width: 3.5cm; background-color: Gainsboro !important;">
WIS (Weighted) interval score
</td>
<td style="text-align:left;background-color: Gainsboro !important;width: 15.5cm; ">
<p>The (weighted) interval score is a proper scoring rule for quantile
forecasts that converges to the crps for an increasing number of
intervals. The score can be decomposed into a sharpness (uncertainty)
component and penalties for over- and underprediction. For a single
interval, the score is computed as <span class="math display">\[IS_\alpha(F,y) = (u-l) + \frac{2}{\alpha} \cdot
(l-y) \cdot 1(y \leq l) + \frac{2}{\alpha} \cdot (y-u) \cdot 1(y \geq
u), \]</span> where <span class="math inline">\(1()\)</span> is the
indicator function, <span class="math inline">\(y\)</span> is the true
value, and <span class="math inline">\(l\)</span> and <span class="math inline">\(u\)</span> are the <span class="math inline">\(\frac{\alpha}{2}\)</span> and <span class="math inline">\(1 - \frac{\alpha}{2}\)</span> quantiles of the
predictive distribution <span class="math inline">\(F\)</span>, i.e. the
lower and upper bound of a single prediction interval. For a set of
<span class="math inline">\(K\)</span> prediction intervals and the
median <span class="math inline">\(m\)</span>, the score is computed as
a weighted sum, <span class="math display">\[WIS = \frac{1}{K + 0.5}
\cdot (w_0 \cdot |y - m| + \sum_{k = 1}^{K} w_k \cdot IS_{\alpha}(F,
y)),\]</span> where <span class="math inline">\(w_k\)</span> is a weight
for every interval. Usually, <span class="math inline">\(w_k =
\frac{\alpha_k}{2}\)</span> and <span class="math inline">\(w_0 =
0.5\)</span>.</p>
<strong>Usage and caveats</strong>: Smaller scores are better.
Applicable to all quantile forecasts, takes the entire predictive
distribution into account. Just as the crps, the wis is based on
measures of absolute error. When averaging across multiple targets, it
will therefore be dominated by targets with higher absolute values. The
decomposition into sharpness, over- and underprediction make it easy to
interpret scores and use them for model improvement.
</td>
</tr>
<tr>
<td style="text-align:left;width: 3.5cm; ">
DSS Dawid-Sebastiani score
</td>
<td style="text-align:left;width: 15.5cm; ">
<p>The Dawid-Sebastiani-Score is a proper scoring rule proposed that
only relies on the first moments of the predictive distribution and is
therefore easy to compute. It is given as</p>
<p><span class="math display">\[\text{dss}(F, y) = \left( \frac{y -
\mu}{\sigma} \right)^2 + 2 \cdot \log \sigma,\]</span> where <span class="math inline">\(F\)</span> is the predictive distribution with
mean <span class="math inline">\(\mu\)</span> and standard deviation
<span class="math inline">\(\sigma\)</span> and <span class="math inline">\(y\)</span> is the true observed value.</p>
<strong>Usage and caveats</strong> The dss is applicable to continuous
and integer forecasts and easy to compute. Apart from the ease of
computation we see little advantage in using it over other scores.
</td>
</tr>
<tr>
<td style="text-align:left;width: 3.5cm; background-color: Gainsboro !important;">
Brier score
</td>
<td style="text-align:left;background-color: Gainsboro !important;width: 15.5cm; ">
<p>Proper scoring rule for binary forecasts. The Brier score is computed
as <span class="math display">\[\text{Brier Score} = \frac{1}{N} \sum_{n
= 1}^{N} (f_n - y_n),\]</span> where <span class="math inline">\(f_n\)</span>, with <span class="math inline">\(n =
1, \dots, N\)</span> are the predicted probablities that the
corresponding events, <span class="math inline">\(y_n \in (0,
1)\)</span> will be equal to one.)</p>
<strong>Usage</strong>: Applicable to all binary forecasts.
</td>
</tr>
<tr>
<td style="text-align:left;width: 3.5cm; ">
Interval coverage
</td>
<td style="text-align:left;width: 15.5cm; ">
<p>Interval coverage measures the proportion of observed values that
fall in a given prediction interval range. Interval coverage for a
single prediction interval range can be calculated as <span class="math display">\[IC_{\alpha} = \text{nominal coverage} -
\text{empirical coverage},\]</span> where nominal coverage is <span class="math inline">\(1 - \alpha\)</span> and empirical coverage is the
proportion of true values actually covered by all <span class="math inline">\(1 - \alpha\)</span> prediction intervals.</p>
<p>To summarise interval coverage over different over multiple interval
ranges, we can compute coverage deviation defined as the mean interval
coverage over all <span class="math inline">\(K\)</span> interval ranges
<span class="math inline">\(\alpha_k\)</span> with <span class="math inline">\(k = 1, \dots, K\)</span>: <span class="math display">\[\text{Coverage deviation} = \frac{1}{K} \sum_{k =
1}^{K} \text{IC}_{\alpha_k}\]</span></p>
<strong>Usage</strong>: Interval coverage for a set of chosen intervals,
(e.g. 50% and 90%) gives a good indication of marginal calibration and
is easy to interpret. Reporting coverage deviation has the advantage of
summarising calibration in a single number, but loses some of the
nuance.
</td>
</tr>
<tr>
<td style="text-align:left;width: 3.5cm; background-color: Gainsboro !important;">
Quantile coverage
</td>
<td style="text-align:left;background-color: Gainsboro !important;width: 15.5cm; ">
<p>Quantile coverage for a given quantile level is the proportion of
true values smaller than the predictions corresponding to that quantile
level.</p>
<strong>Usage</strong>: Quantile coverage is similar to interval
coverage, but conveys more information. For example, it allows us to
look at the 5% and 95% quantile separately, instead of jointly at the
90% prediction interval). This helps to diagnose whether it is the upper
or lower end of a prediction interval that is causing problems. Plots of
quantile coverage are conceptually very similar to PIT histograms.
</td>
</tr>
<tr>
<td style="text-align:left;width: 3.5cm; ">
Probability integral transform (PIT)
</td>
<td style="text-align:left;width: 15.5cm; ">
<p>The probability integral transform (PIT, Dawid 1984) represents a
succinct way to visualise deviations between the predictive distribution
<span class="math inline">\(F\)</span> and the true data-generating
distribution <span class="math inline">\(G\)</span>. The idea is to
transform the observed values such that agreement between forecasts and
data can then be examined by observing whether or not the transformed
values follow a uniform distribution. The PIT is given by <span class="math display">\[u = F (y),\]</span> where <span class="math inline">\(u\)</span> is the transformed variable and <span class="math inline">\(F(y)\)</span> is the predictive distribution <span class="math inline">\(F\)</span> evaluated at the true observed value
<span class="math inline">\(y\)</span>. If <span class="math inline">\(F
= G\)</span>, then <span class="math inline">\(u\)</span> follows a
uniform distribution.</p>
<p>For integer outcomes, the PIT is no longer uniform even when
forecasts are ideal. Instead, a randomised PIT can be used: <span class="math display">\[u = P(y) + v \cdot (P(y) - P(y - 1) ),\]</span>
where <span class="math inline">\(y\)</span> is again the observed value
<span class="math inline">\(P()\)</span> is the cumulative probability
assigned to all values smaller or equal to <span class="math inline">\(y\)</span> (where <span class="math inline">\(P(-1) = 0\)</span> by definition, and <span class="math inline">\(v\)</span> is a standard uniform variable
independent of <span class="math inline">\(y\)</span>. If <span class="math inline">\(P\)</span> is equal to the true data-generating
distribution function, then <span class="math inline">\(u\)</span> is
standard uniform. also propose a non-randomised version of the PIT for
count data that could be used alternatively.</p>
<strong>Usage</strong>: One can plot a histogram of <span class="math inline">\(u\)</span> values to look for deviations from
uniformity. U-shaped histograms often result from predictions that are
too narrow, while hump-shaped histograms indicate that predictions may
be too wide. Biased predictions will usually result in a triangle-shaped
histogram. One can also test for deviations from normality, using for
example an Anderson-Darling test. This, however, proves to be overly
strict in practice and even slight deviations from perfect calibration
are punished in a way that makes it very hard to compare models at all.
In addition, errors from forecasts may be correlated (i.e. forecasts
made on a given date), potentially violating the assumptions of the
Anderson-Darling test. We therefore do not recommend it for most use
cases.
</td>
</tr>
<tr>
<td style="text-align:left;width: 3.5cm; background-color: Gainsboro !important;">
Sharpness
</td>
<td style="text-align:left;background-color: Gainsboro !important;width: 15.5cm; ">
<p>Sharpness is the ability to produce narrow forecasts and is a feature
of the forecasts only and does not depend on the observations. Sharpness
is therefore only of interest conditional on calibration: a very precise
forecast is not useful if it is clearly wrong.</p>
<p>As suggested by Funk et al. (2019), we measure sharpness for
continuous and integer forecasts represented by predictive samples as
the normalised median absolute deviation about the median (MADN) ), i.e.
<span class="math display">\[ S(F) = \frac{1}{0.675} \cdot
\text{median}(|x - \text{median(x)}|), \]</span> where <span class="math inline">\(x\)</span> is the vector of all predictive samples
and <span class="math inline">\(\frac{1}{0.675}\)</span> is a
normalising constant. If the predictive distribution <span class="math inline">\(F\)</span> is the CDF of a normal distribution,
then sharpness will equal the standard deviation of <span class="math inline">\(F\)</span>.</p>
For quantile forecasts we can directly use the sharpness component of
the weighted interval score. Sharpness is then simply the weighted mean
of the widths of the central prediction intervals.
</td>
</tr>
<tr>
<td style="text-align:left;width: 3.5cm; ">
Bias
</td>
<td style="text-align:left;width: 15.5cm; ">
<p>Bias is a measure of the tendency of a forecaster to over- or
underpredict. For continuous forecasts, bias is given as <span class="math display">\[B(F, y) = 1 - 2 \cdot (F (y)), \]</span> where
<span class="math inline">\(F\)</span> is the CDF of the predictive
distribution and <span class="math inline">\(y\)</span> is the observed
value.</p>
<p>For integer-valued forecasts, bias can be calculated as <span class="math display">\[B(P, y) = 1 - (P(y) + P(y + 1)), \]</span> where
<span class="math inline">\(P(y)\)</span> is the cumulative probability
assigned to all outcomes smaller or equal to <span class="math inline">\(y\)</span>.</p>
<p>For quantile forecasts, Bias can be calculated as the maximum
percentile rank for which the prediction is smaller than <span class="math inline">\(y\)</span>, if the true value is smaller than the
median of the predictive distribution. If the true value is above the
median of the predictive distribution, then bias is the minimum
percentile rank for which the corresponding quantile is still larger
than the true value. If the true value is exactly the median, bias is
zero. For a large enough number of quantiles, the percentile rank will
equal the proportion of predictive samples below the observed true
value, and this metric coincides with the one for continuous
forecasts.</p>
<strong>Usage</strong>: In contrast to the over- and underprediction
penalties of the interval score it is bound between 0 and 1 and
represents the tendency of forecasts to be biased rather than the
absolute amount of over- and underprediction. It is therefore a more
robust measurement, but harder to interpet. It largely depends on the
application whether one is more interested in the tendency to be biased
or in the absolute value of over- and underpredictions.
</td>
</tr>
<tr>
<td style="text-align:left;width: 3.5cm; background-color: Gainsboro !important;">
Mean score ratio
</td>
<td style="text-align:left;background-color: Gainsboro !important;width: 15.5cm; ">
<p>The mean score ratio is used to compare two models on the overlapping
set of forecast targets for which both models have made a prediction.
The mean score ratio is calculated as the mean score achieved by the
first model over the mean score achieved by the second model. More
precisely, for two models <span class="math inline">\(i, j\)</span>, we
determine the set of overlapping forecasts, denoted by <span class="math inline">\(\mathcal{A}_{ij}\)</span> and compute the mean
score ratio <span class="math inline">\(\theta_{ij}\)</span> as <span class="math display">\[\theta_{ij} =\frac{\text{mean score model } i
\text{ on } \mathcal{A}_{ij}}{\text{mean score model } j \text{ on }
\mathcal{A}_{ij}}.\]</span> The mean score ratio can in principle be
computed for any arbitrary score.</p>
<strong>Usage</strong>: Mean scores ratios are usually calculated in the
context of pairwise comparisons, where a set of models is compared by
looking at mean score ratios of all possible parings. Whether smaller or
larger values are better depends on the orientation of the original
score used
</td>
</tr>
<tr>
<td style="text-align:left;width: 3.5cm; ">
Relative skill
</td>
<td style="text-align:left;width: 15.5cm; ">
<p>Relative skill scores can be used to obtain a ranking of models based
on pairwise comparisons between all models. To compute the relative
skill <span class="math inline">\(\theta_i\)</span> of model <span class="math inline">\(i\)</span>, we take the geometric mean of all mean
score ratios that involve model <span class="math inline">\(i\)</span>,
i.e. <span class="math display">\[ \theta_{i} = \left(\prod_{m = 1}^M
\theta_{im}\right)^{1/M}, \]</span> where M is the number of models.</p>
<strong>Usage and caveats</strong>: Relative skill is a helpful way to
obtain a model ranking. Whether smaller or larger values are better
depends on the orientation of the original score used. It is in
principle relatively robust against biases that arise when models only
forecast some of the available targets and is a reasonable way to handle
missing forecasts. One possible precautionary measure to reduces issues
with missing forecasts is to only compare models that have forecasted at
least half of all possible targets (this ensures that there is always an
overlap between models). If there is no overlap between models, the
relative skill implicitly estimates how a model would have forecasted on
those missing targets.
</td>
</tr>
</tbody>
</table>
</div>



<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
